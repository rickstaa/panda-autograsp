## Main configuration file for the panda_autograsp solution
# This file contains the configuration values used in the panda_autograsp solution

#################################################
# Panda autograsp main algorithm settings #######
#################################################
main:
  # Grasp computation solution defaults
  solution: gqcnn
  models_dir: ./models # Folder in which models are downloaded

  # Grasp pickup settings
  pickup:
    height: 0.4 # [m]

  # Grasp place settings
  place:
    # Place location (relative to panda_link0)
    # The place where to put the object after it has been successfully grasped.
    # This is relative to the robot base link (panda_link0) the z axis is set equal
    # to the the z location at the moment when the grasp was started.
    pose:
      x_pos: 0.2 # [m]
      y_pos: 0.2 # [m]

#################################################
# Panda_autograsp visualization settings ########
#################################################
vis: # Show grasp images using opencv (Useful for debugging)
  figs: # Grasp computation visualization figures
    rgbd_state: 0
    cropped_rgbd_image: 0
    color_image: 0
    depth_image: 0
    segmask: 0
    final_grasp: 0

#################################################
# Robot parameters ##############################
#################################################
robot:
  gripper_width: 0.08 # [m]
  gripper_center: [0.0, 0.0, 0.12, 0.0, 0.0, 0.0] # (x, y, z, yaw, pitch roll) in [m, rad] Relative to the panda_link8 frame

#################################################
# Moveit planning settings ######################
#################################################
planning:
  general:
    planning_time: 5 # [s] Max number of seconds moveit can spend on the path planning.

  point: # Plan to point
    point_n_step: 5 # The number of times moveit tries to plan to a given point.

  cartesian: # Plan cartesian path.
    eef_step: 0.01 # [m] Interpolation step size.
    jump_threshold: 0.0 # Interpolation scaling factor

#################################################
# Grasp computation algorithm settings ##########
#################################################
grasp_detection:

  # GQCNN grasping solution settings
  gqcnn:

    # GQCNN default values
    defaults:

      # Default model
      # NOTE: Uncomment the model you want to use
      # model: GQCNN-2.0 # Trained on images of objects in simulation
      # model: GQCNN-2.1 # Model fine-tuned on images of objects in clutter
      # model: GQCNN-4.0-PJ # Trained on images of objects in clutter with parameters
      model: FC-GQCNN-4.0-PJ # Improved network trained on images of objects in clutter

    parameters:
      !include ./_cfg/gqcnn_parms.yaml

# Grasp detection solution output settings
grasp_detection_result:
  include_thumbnail: 0 # Include grasp photo thumbnail in output grasp object/
  thumbnail_resize: 0.5 # Resize fraction of thumbnail compared to original sensor image (needs to be between 0 and 1).

#################################################
# Calibration settings ##########################
#################################################
calibration:

  pose_estimation_calib_board: aruco_board # [aruco_board or chessboard]
  calib_try_duration: 30 # How long [s] we should search for the pattern before giving up

  chessboard_settings:
    N_FRAMES: 10  # Number of frames of which to take the median
    N_ROWS: 5  # The number of corners in the y direction.
    N_COLUMNS: 7 # The number of corners in the x direction.
    SQUARE_SIZE: 30 # The size of one square in [mm]
